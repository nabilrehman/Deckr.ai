

import { GoogleGenAI, Modality } from "@google/genai";

const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

export interface BoundingBox {
  x: number;
  y: number;
  width: number;
  height: number;
}

export interface ContentBlock {
  id: number;
  title: string;
  content: string[];
  box: BoundingBox;
}

export interface EditingPlan {
  action: 'rearrange-and-remove' | 'generative-edit';
  targets?: number[]; // IDs of blocks to remove
  contentBlocks?: ContentBlock[];
  slideTitle?: { text: string; box: BoundingBox };
  refinedPrompt?: string; // For generative edits
  sources: any[];
}


const fileToGenerativePart = (base64Data: string) => {
    const match = base64Data.match(/^data:(image\/\w+);base64,(.*)$/);
    if (!match) {
        throw new Error("Invalid base64 image data string.");
    }
    const mimeType = match[1];
    const data = match[2];

    return {
        inlineData: {
            data,
            mimeType,
        },
    };
};

const createMaskFromSelection = async (
    selection: { x: number; y: number; width: number; height: number; naturalWidth: number; naturalHeight: number }
): Promise<string> => {
    const canvas = document.createElement('canvas');
    canvas.width = selection.naturalWidth;
    canvas.height = selection.naturalHeight;
    const ctx = canvas.getContext('2d');

    if (!ctx) {
        throw new Error("Could not create canvas context for mask.");
    }

    ctx.fillStyle = 'black';
    ctx.fillRect(0, 0, canvas.width, canvas.height);

    ctx.fillStyle = 'white';
    ctx.fillRect(selection.x, selection.y, selection.width, selection.height);

    return canvas.toDataURL('image/png');
};

const generateSingleImage = async (model: string, parts: any[], config: any): Promise<string> => {
    const response = await ai.models.generateContent({ model, contents: { parts }, config });
    const candidate = response.candidates?.[0];

    if (!candidate || !candidate.content?.parts || candidate.content.parts.length === 0) {
        const finishReason = candidate?.finishReason;
        if (finishReason === 'SAFETY') {
            throw new Error("Generation failed due to safety settings.");
        }
        if (finishReason === 'RECITATION') {
            throw new Error("Generation failed due to recitation policy.");
        }
        throw new Error(`No image was generated by the AI. (Reason: ${finishReason || 'Unknown'})`);
    }

    for (const part of candidate.content.parts) {
        if (part.inlineData) {
            const base64ImageBytes = part.inlineData.data;
            const mimeType = part.inlineData.mimeType;
            return `data:${mimeType};base64,${base64ImageBytes}`;
        }
    }
    
    throw new Error("No image data found in the AI's response.");
};

export const editImage = async (base64Image: string, prompt: string): Promise<string> => {
    const imagePart = fileToGenerativePart(base64Image);
    const textPart = { text: prompt };
    return generateSingleImage('gemini-2.5-flash-image', [imagePart, textPart], { responseModalities: [Modality.IMAGE] });
};

export const inpaintImage = async (
    base64Image: string,
    selection: { x: number; y: number; width: number; height: number; naturalWidth: number; naturalHeight: number },
    prompt: string
): Promise<string> => {
    const maskBase64 = await createMaskFromSelection(selection);
    const imagePart = fileToGenerativePart(base64Image);
    const maskPart = fileToGenerativePart(maskBase64);
    const inpaintPrompt = `You are an expert image editor performing an inpainting task. You are given three inputs:
1. An original image.
2. A mask image (black with a white area).
3. A text prompt describing a change.
Your task is to edit the original image **only** within the area defined by the white region of the mask. You MUST preserve the rest of the original image perfectly.
The edit to perform within the masked area is: "${prompt}"`;
    const textPart = { text: inpaintPrompt };
    return generateSingleImage('gemini-2.5-flash-image', [imagePart, maskPart, textPart], { responseModalities: [Modality.IMAGE] });
};


export const compositeImage = async (baseImage: string, overlayImage: string, prompt: string): Promise<string> => {
    const baseImagePart = fileToGenerativePart(baseImage);
    const overlayImagePart = fileToGenerativePart(overlayImage);
    const compositePrompt = `Perfectly preserve the first image (the slide). Place the second image (the logo) on top of the first image according to these instructions: ${prompt}. Do not change the slide content, colors, or layout. It's critical that the original slide is preserved.`;
    const textPart = { text: compositePrompt };
    return generateSingleImage('gemini-2.5-flash-image', [baseImagePart, overlayImagePart, textPart], { responseModalities: [Modality.IMAGE] });
};

export const createEditingPlan = async (prompt: string, base64Image: string): Promise<EditingPlan> => {
    try {
        const systemPrompt = `You are a world-class AI agent acting as a "Design Analyst". Your job is to analyze a slide image and a user's request to create a structured JSON plan for an automated editing engine. You have two main tasks: 'rearrange-and-remove' for complex layouts, and 'generative-edit' for all other creative tasks.

**Your Process:**
1.  **Analyze the Image:** The provided slide image is your ONLY source of truth. Use your vision to perform OCR and identify all major content blocks (e.g., titled columns, text boxes). For each block, determine its sequential ID (starting from 1), its title, its text content (as an array of strings), and its precise bounding box (\`{x, y, width, height}\`). Also identify the main slide title and its bounding box.
2.  **Analyze the User's Request:** Understand the user's core intent.
3.  **Choose an Action:**
    *   If the user's request involves removing, reordering, or rearranging major content blocks (like columns), you MUST choose the \`'rearrange-and-remove'\` action.
    *   For ALL other requests (adding logos, changing text color, adding new items, creative changes), you MUST choose the \`'generative-edit'\` action.
4.  **Construct the JSON Output:** Based on the action, construct a single, valid JSON object.

**JSON Schema for \`action: 'rearrange-and-remove'\`:**
{
  "action": "rearrange-and-remove",
  "targets": [/* Array of integer IDs of the blocks to REMOVE */],
  "contentBlocks": [
    { "id": 1, "title": "...", "content": ["..."], "box": { "x": 0, "y": 0, "width": 0, "height": 0 } },
    /* ... one object for EVERY identified block on the original slide */
  ],
  "slideTitle": { "text": "...", "box": { "x": 0, "y": 0, "width": 0, "height": 0 } }
}

**JSON Schema for \`action: 'generative-edit'\`:**
{
  "action": "generative-edit",
  "refinedPrompt": "/* Your expertly crafted, high-fidelity prompt for the image model, based on a visual analysis of the slide and the user's request. Preserve style, fonts, and colors meticulously. Handle list manipulation (add, remove, renumber) by defining the final desired state of the list. */"
}
---
**User's Request:** "${prompt}"`;
        
        const imagePart = fileToGenerativePart(base64Image);
        const textPart = { text: systemPrompt };

        const response = await ai.models.generateContent({
            model: "gemini-2.5-flash",
            contents: { parts: [imagePart, textPart] },
        });

        const sources = response.candidates?.[0]?.groundingMetadata?.groundingChunks || [];
        const jsonText = response.text.trim();

        let parsedResult: Partial<EditingPlan>;

        try {
            const cleanJsonText = jsonText.replace(/^```json\s*|```\s*$/g, '');
            parsedResult = JSON.parse(cleanJsonText);
        } catch (e) {
            console.warn("Failed to parse JSON plan from AI, falling back to generative edit.", e, "Raw text:", jsonText);
            // Fallback: create a simple one-step plan with the user's original prompt.
            return { action: 'generative-edit', refinedPrompt: prompt, sources: [] };
        }
        
        return { ...parsedResult, sources } as EditingPlan;

    } catch (error) {
        console.error("Error creating editing plan with Gemini:", error);
        // Fallback to original prompt on error
        return { action: 'generative-edit', refinedPrompt: prompt, sources: [] };
    }
};