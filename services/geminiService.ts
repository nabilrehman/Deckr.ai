
import { GoogleGenAI, Modality } from "@google/genai";

const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

export interface RefinedPrompt {
    refinedPrompt: string;
    sources: any[];
}


const fileToGenerativePart = (base64Data: string) => {
    const match = base64Data.match(/^data:(image\/\w+);base64,(.*)$/);
    if (!match) {
        throw new Error("Invalid base64 image data string.");
    }
    const mimeType = match[1];
    const data = match[2];

    return {
        inlineData: {
            data,
            mimeType,
        },
    };
};

const createMaskFromSelection = async (
    selection: { x: number; y: number; width: number; height: number; naturalWidth: number; naturalHeight: number }
): Promise<string> => {
    const canvas = document.createElement('canvas');
    canvas.width = selection.naturalWidth;
    canvas.height = selection.naturalHeight;
    const ctx = canvas.getContext('2d');

    if (!ctx) {
        throw new Error("Could not create canvas context for mask.");
    }

    ctx.fillStyle = 'black';
    ctx.fillRect(0, 0, canvas.width, canvas.height);

    ctx.fillStyle = 'white';
    ctx.fillRect(selection.x, selection.y, selection.width, selection.height);

    return canvas.toDataURL('image/png');
};

const generateSingleImage = async (model: string, parts: any[], config: any): Promise<string> => {
    const response = await ai.models.generateContent({ model, contents: { parts }, config });
    const candidate = response.candidates?.[0];

    if (!candidate || !candidate.content?.parts || candidate.content.parts.length === 0) {
        const finishReason = candidate?.finishReason;
        if (finishReason === 'SAFETY') {
            throw new Error("Generation failed due to safety settings.");
        }
        if (finishReason === 'RECITATION') {
            throw new Error("Generation failed due to recitation policy.");
        }
        throw new Error(`No image was generated by the AI. (Reason: ${finishReason || 'Unknown'})`);
    }

    for (const part of candidate.content.parts) {
        if (part.inlineData) {
            const base64ImageBytes = part.inlineData.data;
            const mimeType = part.inlineData.mimeType;
            return `data:${mimeType};base64,${base64ImageBytes}`;
        }
    }
    
    throw new Error("No image data found in the AI's response.");
};

export const editImage = async (base64Image: string, prompt: string): Promise<string> => {
    const imagePart = fileToGenerativePart(base64Image);
    const textPart = { text: prompt };
    return generateSingleImage('gemini-2.5-flash-image', [imagePart, textPart], { responseModalities: [Modality.IMAGE] });
};

export const inpaintImage = async (
    base64Image: string,
    selection: { x: number; y: number; width: number; height: number; naturalWidth: number; naturalHeight: number },
    prompt: string
): Promise<string> => {
    const maskBase64 = await createMaskFromSelection(selection);
    const imagePart = fileToGenerativePart(base64Image);
    const maskPart = fileToGenerativePart(maskBase64);
    const inpaintPrompt = `You are an expert image editor performing an inpainting task. You are given three inputs:
1. An original image.
2. A mask image (black with a white area).
3. A text prompt describing a change.
Your task is to edit the original image **only** within the area defined by the white region of the mask. You MUST preserve the rest of the original image perfectly.
The edit to perform within the masked area is: "${prompt}"`;
    const textPart = { text: inpaintPrompt };
    return generateSingleImage('gemini-2.5-flash-image', [imagePart, maskPart, textPart], { responseModalities: [Modality.IMAGE] });
};


export const compositeImage = async (baseImage: string, overlayImage: string, prompt: string): Promise<string> => {
    const baseImagePart = fileToGenerativePart(baseImage);
    const overlayImagePart = fileToGenerativePart(overlayImage);
    const compositePrompt = `Perfectly preserve the first image (the slide). Place the second image (the logo) on top of the first image according to these instructions: ${prompt}. Do not change the slide content, colors, or layout. It's critical that the original slide is preserved.`;
    const textPart = { text: compositePrompt };
    return generateSingleImage('gemini-2.5-flash-image', [baseImagePart, overlayImagePart, textPart], { responseModalities: [Modality.IMAGE] });
};

export const researchAndRefinePrompt = async (prompt: string, base64Image: string): Promise<RefinedPrompt> => {
    try {
        const systemPrompt = `You are a world-class AI agent strategist with vision. Your job is to analyze a user's request and the provided slide image to create a perfect, actionable prompt for a generative image model.

**Core Principles:**
1.  **Analyze the Image First:** The provided slide image is your primary source of truth. Read its content, understand its layout, and identify its visual style (fonts, colors, logos).
2.  **Describe the Final State:** Your prompt must describe the **FINAL, DESIRED STATE**. Do not give sequential instructions like "First do X, then do Y." This confuses the image model.
3.  **Preserve Fidelity:** This is your most important rule. Your prompt must instruct the image model to preserve the original slide's style with 100% accuracy. This includes all original text, fonts, colors, logos, and visual elements unless they are the specific target of the edit.

**How to Handle List Manipulation (A Critical Task):**
*   When a user asks to add, remove, or modify items in a list, your primary job is to use your vision to figure out what the **final, correct version of the list** should be.
*   Your refined prompt must then describe this final state with extreme precision.
*   **Example for a "remove and renumber" request:** A user wants to remove items 3 and 4 from a 5-item list. You must analyze the image to find the content for items 1, 2, and 5. Then, you must construct a prompt like this: "Recreate this slide to contain only three numbered items. The items, in sequential order, must be '01 [Content of original item 1]', '02 [Content of original item 2]', and '03 [Content of original item 5]'. It is absolutely critical that the final numbering is sequential and the style perfectly matches the original."

**Output Format:**
You MUST return a single, valid JSON object with one key:
*   "refinedPrompt": A string containing your final, expertly crafted prompt for the image model.

---
**User's Request:** "${prompt}"`;
        
        const imagePart = fileToGenerativePart(base64Image);
        const textPart = { text: systemPrompt };

        const response = await ai.models.generateContent({
            model: "gemini-2.5-flash",
            contents: { parts: [imagePart, textPart] },
        });

        const sources = response.candidates?.[0]?.groundingMetadata?.groundingChunks || [];
        const jsonText = response.text.trim();

        let parsedResult: { refinedPrompt: string };

        try {
            const cleanJsonText = jsonText.replace(/^```json\s*|```\s*$/g, '');
            parsedResult = JSON.parse(cleanJsonText);
        } catch (e) {
            console.warn("Failed to parse JSON plan from AI, falling back to a single step.", e, "Raw text:", jsonText);
            // Fallback: create a simple one-step plan with the user's original prompt.
            return { refinedPrompt: prompt, sources: [] };
        }
        
        return { ...parsedResult, sources };

    } catch (error) {
        console.error("Error refining prompt with Gemini:", error);
        // Fallback to original prompt on error
        return { refinedPrompt: prompt, sources: [] };
    }
};
